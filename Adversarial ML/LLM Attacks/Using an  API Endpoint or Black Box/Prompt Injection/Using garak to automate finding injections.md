---
tags:
  - vulnerability-scanner
  - llm-attacks
  - prompt-injection
  - black-box
  - garak
aliases:
  - garak
transferable: "True"
last_tested: 08/2023
---

## **PoC:**

https://github.com/leondz/garak

## **Details**
`garak` checks if an LLM can be made to fail in an way we don't want. `garak` probes for hallucination, data leakage, prompt injection, misinformation, toxicity generation, jailbreaks, and many other weaknesses. If you know `nmap`, it's `nmap` for LLMs.
Best used directly. 

[Great usage video by embrace the red](https://www.youtube.com/watch?v=f713_sFqItY) 